{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Process-CCSs\" data-toc-modified-id=\"Process-CCSs-1\">Process CCSs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1.1\">Setup</a></span></li><li><span><a href=\"#PacBio-amplicons\" data-toc-modified-id=\"PacBio-amplicons-1.2\">PacBio amplicons</a></span></li><li><span><a href=\"#CCS-stats-for-PacBio-runs\" data-toc-modified-id=\"CCS-stats-for-PacBio-runs-1.3\">CCS stats for PacBio runs</a></span></li><li><span><a href=\"#Align-CCSs-to-amplicons\" data-toc-modified-id=\"Align-CCSs-to-amplicons-1.4\">Align CCSs to amplicons</a></span></li><li><span><a href=\"#Write-valid-CCSs\" data-toc-modified-id=\"Write-valid-CCSs-1.5\">Write valid CCSs</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process CCSs\n",
    "This Python Jupyter notebook processes the PacBio circular consensus sequences (CCSs) to extract barcodes and call mutations in the gene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import Python modules\n",
    "\n",
    "Plotting is done with [plotnine](https://plotnine.readthedocs.io/en/stable/), which uses ggplot2-like syntax.\n",
    "\n",
    "The analysis uses the Bloom lab's [alignparse](https://jbloomlab.github.io/alignparse) and [dms_variants](https://jbloomlab.github.io/dms_variants) packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import alignparse\n",
    "import alignparse.ccs\n",
    "from alignparse.constants import CBPALETTE\n",
    "import alignparse.minimap2\n",
    "import alignparse.targets\n",
    "\n",
    "import dms_variants\n",
    "import dms_variants.plotnine_themes\n",
    "import dms_variants.utils\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set [plotnine](https://plotnine.readthedocs.io/en/stable/) theme to the one defined in [dms_variants](https://jbloomlab.github.io/dms_variants):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_set(dms_variants.plotnine_themes.theme_graygrid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versions of key software:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using alignparse version {alignparse.__version__}\")\n",
    "print(f\"Using dms_variants version {dms_variants.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore warnings that clutter output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make output directory for figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config['figs_dir'], exist_ok=True)\n",
    "os.makedirs(config['process_ccs_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PacBio amplicons\n",
    "Get the amplicons sequenced by PacBio as the alignment target along with the specs on how to parse the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reading amplicons from {config['amplicons']}\")\n",
    "print(f\"Reading feature parse specs from {config['feature_parse_specs']}\")\n",
    "\n",
    "targets = alignparse.targets.Targets(\n",
    "                seqsfile=config['amplicons'],\n",
    "                feature_parse_specs=config['feature_parse_specs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the target amplicons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = targets.plot(ax_width=7,\n",
    "                   plots_indexing='biopython',  # numbering starts at 0\n",
    "                   ax_height=2,  # height of each plot\n",
    "                   hspace=1.2,  # vertical space between plots\n",
    "                   )\n",
    "\n",
    "plotfile = os.path.join(config['figs_dir'], 'amplicons.pdf')\n",
    "print(f\"Saving plot to {plotfile}\")\n",
    "fig.savefig(plotfile, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out the specs used to parse the features (these are the same specs provided as `feature_parse_specs` when initializing `targets`, but with defaults filled in):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets.feature_parse_specs('yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCS stats for PacBio runs\n",
    "Read data frame with information on PacBio runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacbio_runs = (\n",
    "    pd.read_csv(config['pacbio_runs'], dtype=str)\n",
    "    .drop(columns=['subreads'])\n",
    "    .assign(name=lambda x: x['library'] + '_' + x['run'],\n",
    "            fastq=lambda x: config['ccs_dir'] + '/' + x['name'] + '_ccs.fastq'\n",
    "            )\n",
    "    )\n",
    "\n",
    "# we only have report files on the Hutch server, not for SRA download\n",
    "if config['seqdata_source'] == 'HutchServer':\n",
    "    pacbio_runs = (\n",
    "        pacbio_runs\n",
    "        .assign(report=lambda x: config['ccs_dir'] + '/' + x['name'] + '_report.txt')\n",
    "        )\n",
    "    report_col = 'report'\n",
    "elif config['seqdata_source'] == 'SRA':\n",
    "    report_col = None\n",
    "else:\n",
    "    raise ValueError(f\"invalid `seqdata_source` {config['seqdata_source']}\")\n",
    "\n",
    "display(HTML(pacbio_runs.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object that summarizes the `ccs` runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_summaries = alignparse.ccs.Summaries(pacbio_runs,\n",
    "                                         report_col=report_col,\n",
    "                                         ncpus=config['max_cpus'],\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If available, plot statistics on the number of ZMWs for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ccs_summaries.has_zmw_stats():\n",
    "    p = ccs_summaries.plot_zmw_stats()\n",
    "    p = p + theme(panel_grid_major_x=element_blank())  # no vertical grid lines\n",
    "    _ = p.draw()\n",
    "else:\n",
    "    print('No ZMW stats available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot statistics on generated CCSs: their length, number of subread passes, and accuracy (as reported by the `ccs` program):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in ['length', 'passes', 'accuracy']:\n",
    "    if ccs_summaries.has_stat(variable):\n",
    "        p = ccs_summaries.plot_ccs_stats(variable, maxcol=7, bins=25)\n",
    "        p = p + theme(panel_grid_major_x=element_blank())  # no vertical grid lines\n",
    "        _ = p.draw()\n",
    "    else:\n",
    "        print(f\"No {variable} statistics available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align CCSs to amplicons\n",
    "We now align the CCSs to the amplicon and parse features from the resulting alignments using the specs above.\n",
    "\n",
    "First, we initialize an `alignparse.minimap2.Mapper` to align the reads to SAM files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = alignparse.minimap2.Mapper(alignparse.minimap2.OPTIONS_CODON_DMS)\n",
    "\n",
    "print(f\"Using `minimap2` {mapper.version} with these options:\\n\" +\n",
    "      ' '.join(mapper.options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use `Targets.align_and_parse` to create the alignments and parse them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readstats, aligned, filtered = targets.align_and_parse(\n",
    "        df=pacbio_runs,\n",
    "        mapper=mapper,\n",
    "        outdir=config['process_ccs_dir'],\n",
    "        name_col='run',\n",
    "        group_cols=['name', 'library'],\n",
    "        queryfile_col='fastq',\n",
    "        overwrite=True,\n",
    "        ncpus=config['max_cpus'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, examine the read stats from the alignment / parsing, both extracting alignment target name and getting stats aggregated by target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readstats = (\n",
    "    readstats\n",
    "    .assign(category_all_targets=lambda x: x['category'].str.split().str[0],\n",
    "            target=lambda x: x['category'].str.split(None, 1).str[1],\n",
    "            valid=lambda x: x['category_all_targets'] == 'aligned')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the read stats by run (combining all targets and libraries within a run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 7\n",
    "p = (\n",
    "    ggplot(readstats\n",
    "           .groupby(['name', 'category_all_targets', 'valid'])\n",
    "           .aggregate({'count': 'sum'})\n",
    "           .reset_index(),\n",
    "           aes('category_all_targets', 'count', fill='valid')) +\n",
    "    geom_bar(stat='identity') +\n",
    "    facet_wrap('~ name', ncol=ncol) +\n",
    "    theme(axis_text_x=element_text(angle=90),\n",
    "          figure_size=(1.85 * min(ncol, len(pacbio_runs)),\n",
    "                       2 * math.ceil(len(pacbio_runs) / ncol)),\n",
    "          panel_grid_major_x=element_blank(),\n",
    "          legend_position='none',\n",
    "          ) +\n",
    "    scale_fill_manual(values=CBPALETTE)\n",
    "    )\n",
    "_ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the read stats by library (combining all targets and runs within a library):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    ggplot(readstats\n",
    "           .groupby(['library', 'category_all_targets', 'valid'])\n",
    "           .aggregate({'count': 'sum'})\n",
    "           .reset_index(), \n",
    "           aes('category_all_targets', 'count', fill='valid')) +\n",
    "    geom_bar(stat='identity') +\n",
    "    facet_wrap('~ library', nrow=1) +\n",
    "    theme(axis_text_x=element_text(angle=90),\n",
    "          figure_size=(1.5 * pacbio_runs['library'].nunique(), 2),\n",
    "          panel_grid_major_x=element_blank(),\n",
    "          legend_position='none',\n",
    "          ) +\n",
    "    scale_fill_manual(values=CBPALETTE)\n",
    "    )\n",
    "_ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the number of reads by target (combining all libraries and runs for a target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    ggplot(readstats\n",
    "           .groupby(['target'])\n",
    "           .aggregate({'count': 'sum'})\n",
    "           .reset_index(), \n",
    "           aes('target', 'count')) +\n",
    "    geom_point(stat='identity', size=3) +\n",
    "    theme(axis_text_x=element_text(angle=90),\n",
    "          figure_size=(0.3 * readstats['target'].nunique(), 2),\n",
    "          panel_grid_major_x=element_blank(),\n",
    "          ) +\n",
    "    scale_y_log10(name='number of reads')\n",
    "    )\n",
    "_ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And read stats by target (combining all libraries and runs for a target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    ggplot(readstats\n",
    "           .groupby(['target', 'valid'])\n",
    "           .aggregate({'count': 'sum'})\n",
    "           .reset_index()\n",
    "           .assign(total=lambda x: x.groupby('target')['count'].transform('sum'),\n",
    "                   frac=lambda x: x['count'] / x['total'],\n",
    "                   ), \n",
    "           aes('target', 'frac', fill='valid')) +\n",
    "    geom_bar(stat='identity') +\n",
    "    theme(axis_text_x=element_text(angle=90),\n",
    "          figure_size=(0.5 * readstats['target'].nunique(), 2),\n",
    "          panel_grid_major_x=element_blank(),\n",
    "          ) +\n",
    "    scale_fill_manual(values=CBPALETTE)\n",
    "    )\n",
    "_ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see **why** we filtered the reads.\n",
    "First, we do some transformations on the `filtered` dict returned by `Targets.align_and_parse`.\n",
    "Then we count up the number of CCSs filtered for each reason, and group together \"unusual\" reasons that represent less than some fraction of all filtering.\n",
    "For now, we group together all targets to the stats represent all targets combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cutoff = 0.02  # group as \"other\" reasons with <= this frac\n",
    "\n",
    "filtered_df = (\n",
    "    pd.concat(df.assign(target=target) for target, df in filtered.items())\n",
    "    .groupby(['library', 'name', 'run', 'filter_reason'])\n",
    "    .size()\n",
    "    .rename('count')\n",
    "    .reset_index()\n",
    "    .assign(tot_reason_frac=lambda x: (x.groupby('filter_reason')['count']\n",
    "                                       .transform('sum')) / x['count'].sum(),\n",
    "            filter_reason=lambda x: numpy.where(x['tot_reason_frac'] > other_cutoff,\n",
    "                                                x['filter_reason'],\n",
    "                                                'other')\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the filtering reason for all runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 7\n",
    "nreasons = filtered_df['filter_reason'].nunique()\n",
    "\n",
    "p = (\n",
    "    ggplot(filtered_df, aes('filter_reason', 'count')) +\n",
    "    geom_bar(stat='identity') +\n",
    "    facet_wrap('~ name', ncol=ncol) +\n",
    "    theme(axis_text_x=element_text(angle=90),\n",
    "          figure_size=(0.25 * nreasons * min(ncol, len(pacbio_runs)),\n",
    "                       2 * math.ceil(len(pacbio_runs) / ncol)),\n",
    "          panel_grid_major_x=element_blank(),\n",
    "          )\n",
    "    )\n",
    "_ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a similar plot to above, but combine all the runs for each library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    ggplot(filtered_df\n",
    "           .groupby(['library', 'filter_reason'])\n",
    "           .aggregate({'count': 'sum'})\n",
    "           .reset_index(),\n",
    "           aes('filter_reason', 'count')) +\n",
    "    geom_bar(stat='identity') +\n",
    "    facet_wrap('~ library', nrow=1) +\n",
    "    theme(axis_text_x=element_text(angle=90),\n",
    "          figure_size=(0.3 * nreasons * pacbio_runs['library'].nunique(), 2),\n",
    "          panel_grid_major_x=element_blank(),\n",
    "          )\n",
    "    )\n",
    "_ = p.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we take the successfully parsed alignments and read them into a data frame, keeping track of the target that each CCS aligns to.\n",
    "We also drop the pieces of information we won't use going forward, and rename a few columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aligned_df = (\n",
    "    pd.concat(df.assign(target=target) for target, df in aligned.items())\n",
    "    .drop(columns=['query_clip5', 'query_clip3', 'run','name'])\n",
    "    .rename(columns={'barcode_sequence': 'barcode'})\n",
    "    )\n",
    "\n",
    "print(f\"First few lines of information on the parsed alignments:\")\n",
    "display(HTML(aligned_df.head().to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write valid CCSs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the processed CCSs to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_df.to_csv(config['processed_ccs_file'], index=False)\n",
    "\n",
    "print(\"Barcodes and mutations for valid processed CCSs \"\n",
    "      f\"have been written to {config['processed_ccs_file']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we analyze these processed CCSs to build the variants."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.628px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
